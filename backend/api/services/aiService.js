const { GoogleGenerativeAI } = require("@google/generative-ai");
const ModelModel = require("../models/modelModel");

/**
 * ü§ñ AI Service - K·∫øt n·ªëi v·ªõi c√°c AI models t·ª´ database
 */
class AIService {
  constructor() {
    this.modelInstances = new Map(); // Cache c√°c instance AI models
  }

  /**
   * üß© L·∫•y instance AI model t·ª´ cache ho·∫∑c t·∫°o m·ªõi
   * @param {number} modelId - ID c·ªßa model trong database
   * @returns {object|null} - Instance c·ªßa AI model
   */
  async getModelInstance(modelId) {
    try {
      // Ki·ªÉm tra cache tr∆∞·ªõc
      if (this.modelInstances.has(modelId)) {
        return this.modelInstances.get(modelId);
      }

      // L·∫•y th√¥ng tin model t·ª´ database
      const modelInfo = await ModelModel.getModelById(modelId);
      if (!modelInfo) {
        console.error(`Model with ID ${modelId} not found in database`);
        return null;
      }

      console.log(`üîÑ Initializing AI model: ${modelInfo.Name} (ID: ${modelId})`);

      let modelInstance = null;

      // X√°c ƒë·ªãnh lo·∫°i AI model v√† kh·ªüi t·∫°o
      if (modelInfo.Name.toLowerCase().includes('gemini')) {
        // Kh·ªüi t·∫°o Google Gemini
        if (!modelInfo.Api_Key) {
          console.error(`Missing API key for Gemini model ${modelInfo.Name}`);
          return null;
        }

        try {
          const genAI = new GoogleGenerativeAI(modelInfo.Api_Key);
          
          // X√°c ƒë·ªãnh model name ph√π h·ª£p
          let modelName = "gemini-2.5-flash"; // default
          if (modelInfo.Name.toLowerCase().includes('pro')) {
            modelName = "gemini-2.5-pro";
          } else if (modelInfo.Name.toLowerCase().includes('flash')) {
            modelName = "gemini-2.5-flash";
          }

          modelInstance = {
            type: 'gemini',
            name: modelInfo.Name,
            client: genAI,
            modelName: modelName,
            apiKey: modelInfo.Api_Key,
            description: modelInfo.description
          };

          console.log(`‚úÖ Gemini model initialized: ${modelName}`);
        } catch (error) {
          console.error(`Error initializing Gemini model:`, error);
          return null;
        }
      } 
      // C√≥ th·ªÉ m·ªü r·ªông cho ChatGPT, Claude, v.v.
      else if (modelInfo.Name.toLowerCase().includes('chatgpt') || modelInfo.Name.toLowerCase().includes('gpt')) {
        // TODO: Implement ChatGPT integration
        console.warn(`ChatGPT integration not implemented yet for model: ${modelInfo.Name}`);
        return null;
      }
      else if (modelInfo.Name.toLowerCase().includes('claude')) {
        // TODO: Implement Claude integration  
        console.warn(`Claude integration not implemented yet for model: ${modelInfo.Name}`);
        return null;
      }
      else {
        console.warn(`Unknown AI model type: ${modelInfo.Name}`);
        return null;
      }

      // L∆∞u v√†o cache
      if (modelInstance) {
        this.modelInstances.set(modelId, modelInstance);
      }

      return modelInstance;
    } catch (error) {
      console.error(`Error getting model instance for ID ${modelId}:`, error);
      return null;
    }
  }

  /**
   * üß© Generate response t·ª´ AI model
   * @param {number} modelId - ID c·ªßa model trong database
   * @param {string} prompt - Prompt g·ª≠i cho AI
   * @param {array} history - L·ªãch s·ª≠ chat (optional)
   * @param {object} imageData - D·ªØ li·ªáu ·∫£nh n·∫øu c√≥ (optional)
   * @returns {object} - Response t·ª´ AI
   */
  async generateResponse(modelId, prompt, history = [], imageData = null) {
    try {
      const modelInstance = await this.getModelInstance(modelId);
      if (!modelInstance) {
        return {
          success: false,
          error: `AI model with ID ${modelId} not available`
        };
      }

      console.log(`üöÄ Generating response with ${modelInstance.name}...`);

      let response = null;

      if (modelInstance.type === 'gemini') {
        response = await this.generateGeminiResponse(modelInstance, prompt, history, imageData);
      }
      // Th√™m c√°c lo·∫°i AI kh√°c ·ªü ƒë√¢y
      else {
        return {
          success: false,
          error: `AI model type ${modelInstance.type} not supported`
        };
      }

      console.log(`‚úÖ Response generated successfully with ${modelInstance.name}`);
      return response;
    } catch (error) {
      console.error(`Error generating response with model ID ${modelId}:`, error);
      return {
        success: false,
        error: error.message || 'Unknown error occurred'
      };
    }
  }

  /**
   * üß© Generate response t·ª´ Gemini
   * @param {object} modelInstance - Instance c·ªßa Gemini model
   * @param {string} prompt - Prompt g·ª≠i cho AI
   * @param {array} history - L·ªãch s·ª≠ chat
   * @param {object} imageData - D·ªØ li·ªáu ·∫£nh n·∫øu c√≥
   * @returns {object} - Response t·ª´ Gemini
   */
  async generateGeminiResponse(modelInstance, prompt, history = [], imageData = null) {
    try {
      const { client, modelName } = modelInstance;
      let contents = [];

      // N·∫øu c√≥ ·∫£nh, s·ª≠ d·ª•ng Gemini Vision
      if (imageData) {
        const imagePart = {
          inlineData: {
            data: imageData.base64Data,
            mimeType: imageData.mimeType
          }
        };

        const textPart = { text: prompt };
        contents = [{ role: "user", parts: [textPart, imagePart] }];
      } else {
        // X√¢y d·ª±ng conversation history
        if (history && history.length > 0) {
          contents = history.map(item => ({
            role: item.role || "user",
            parts: [{ text: item.text || item.content }]
          }));
        }
        
        // Th√™m prompt hi·ªán t·∫°i
        contents.push({
          role: "user",
          parts: [{ text: prompt }]
        });
      }

      // G·ª≠i request ƒë·∫øn Gemini
      const model = client.getGenerativeModel({ model: modelName });
      const result = await model.generateContent({
        contents: contents
      });

      const responseText = result.response?.text();
      
      if (!responseText) {
        return {
          success: false,
          error: 'No response text from Gemini'
        };
      }

      return {
        success: true,
        data: {
          text: responseText,
          model: modelInstance.name,
          modelId: modelInstance.modelId,
          tokens: result.response?.usageMetadata || null
        }
      };
    } catch (error) {
      console.error(`Error in Gemini response generation:`, error);
      return {
        success: false,
        error: error.message || 'Gemini API error'
      };
    }
  }

  /**
   * üß© Clear cache cho m·ªôt model c·ª• th·ªÉ
   * @param {number} modelId - ID c·ªßa model c·∫ßn clear cache
   */
  clearModelCache(modelId) {
    if (this.modelInstances.has(modelId)) {
      this.modelInstances.delete(modelId);
      console.log(`üóëÔ∏è Cleared cache for model ID: ${modelId}`);
    }
  }

  /**
   * üß© Clear to√†n b·ªô cache
   */
  clearAllCache() {
    this.modelInstances.clear();
    console.log(`üóëÔ∏è Cleared all AI model cache`);
  }

  /**
   * üß© L·∫•y danh s√°ch models ƒë√£ cache
   */
  getCachedModels() {
    return Array.from(this.modelInstances.keys());
  }

  /**
   * üß© Ki·ªÉm tra xem model c√≥ available kh√¥ng
   * @param {number} modelId - ID c·ªßa model
   * @returns {boolean} - True n·∫øu model available
   */
  async isModelAvailable(modelId) {
    const modelInstance = await this.getModelInstance(modelId);
    return modelInstance !== null;
  }
}

// Export singleton instance
const aiService = new AIService();
module.exports = aiService;